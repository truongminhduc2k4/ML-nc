# ğŸš€ QUICK START - HÆ°á»›ng Dáº«n Nhanh

## âœ… Há»‡ Thá»‘ng ÄÃ£ Sáºµn SÃ ng!

Chess AI MCTS project vá»›i cáº£i tiáº¿n Minimax (Opening Book + Advanced Evaluation) Ä‘Ã£ hoÃ n thÃ nh.

---

## ğŸ® Cháº¡y Demo Nhanh

### 1ï¸âƒ£ Demo: MCTS vs Random (32 giÃ¢y)
```bash
cd d:\ML-nc\chess_ai_mcts
D:\ML-nc\.venv\Scripts\python.exe demo_game.py
```
âœ“ Káº¿t quáº£: WHITE WIN - 87 moves

### 2ï¸âƒ£ Kiá»ƒm Thá»­ Cáº£i Tiáº¿n (30 giÃ¢y)
```bash
D:\ML-nc\.venv\Scripts\python.exe test_improvements.py
```
âœ“ Opening Book: 205x faster
âœ“ Advanced Evaluation: 5 factors
âœ“ MCTS vs Random: DRAW
âœ“ Minimax vs Random: DRAW

### 3ï¸âƒ£ Evaluation ToÃ n Bá»™
```bash
D:\ML-nc\.venv\Scripts\python.exe run_evaluation.py
```

---

## ğŸ“š CÃ i Äáº·t & Cáº¥u HÃ¬nh

### KÃ­ch Hoáº¡t Virtual Environment
```bash
D:\ML-nc\.venv\Scripts\Activate.ps1
```

### CÃ i Äáº·t Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ¯ Sá»­ Dá»¥ng Agents

### Quick Example: Minimax (Cáº£i Tiáº¿n) vs Random
```python
from src.chess_engine import ChessGame
from src.agents import MinimaxAgent, RandomAgent

# Táº¡o agents
white = MinimaxAgent(depth=2, use_opening_book=True)
black = RandomAgent()

# ChÆ¡i trÃ² chÆ¡i
game = ChessGame(white_agent=white, black_agent=black)
result = game.play()

# Káº¿t quáº£
print(f"Result: {result}")  # 1=White, -1=Black, 0=Draw
print(f"Moves: {len(game.game.move_stack)}")
print(f"Time: {game.elapsed_time:.1f}s")
```

### CÃ¡c Agent CÃ³ Sáºµn
```python
from src.agents import (
    MinimaxAgent,      # Minimax + Opening Book
    MCTSAgent,         # Monte Carlo Tree Search
    RandomAgent,       # Random moves
)

# Minimax variations
agent1 = MinimaxAgent(depth=2, use_opening_book=True)   # WITH improvements
agent2 = MinimaxAgent(depth=2, use_opening_book=False)  # WITHOUT improvements
agent3 = MinimaxAgent(depth=3, use_opening_book=True)   # Deeper search

# MCTS variations
mcts1 = MCTSAgent(iterations=10)
mcts2 = MCTSAgent(iterations=30)
mcts3 = MCTSAgent(iterations=50)
```

---

## ğŸ“Š Káº¿t Quáº£ Mong Äá»£i

| TrÃ² ChÆ¡i | Káº¿t Quáº£ | NÆ°á»›c | Thá»i Gian |
|---------|---------|------|-----------|
| MCTS(30) vs Random | DRAW | 300-500 | 30-60s âœ“ |
| Minimax(2) vs Random | DRAW/WIN | 300-500 | 30-60s âœ“ |
| Minimax(3) vs Random | WIN | 200-400 | 100-200s âœ“ |

---

## ğŸ“ File Quan Trá»ng

```
chess_ai_mcts/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents.py        â† Minimax, MCTS, Random
â”‚   â”œâ”€â”€ chess_engine.py  â† Chess logic
â”‚   â”œâ”€â”€ mcts.py          â† MCTS algorithm
â”‚   â”œâ”€â”€ openings.py      â† Opening book (NEW)
â”‚   â””â”€â”€ evaluation.py    â† Evaluation framework
â”‚
â”œâ”€â”€ demo_game.py         â† Quick demo
â”œâ”€â”€ test_improvements.py â† Test improvements
â”œâ”€â”€ run_evaluation.py    â† Full evaluation
â”‚
â””â”€â”€ REPORTS
    â”œâ”€â”€ RESULTS_SUMMARY.md
    â”œâ”€â”€ DEPLOYMENT_REPORT.txt
    â””â”€â”€ MINIMAX_IMPROVEMENTS.txt
```

---

## ğŸ”§ Troubleshooting

**ImportError?** â†’ Cháº¡y tá»« thÆ° má»¥c project root
```bash
cd D:\ML-nc\chess_ai_mcts
```

**Python not found?** â†’ KÃ­ch hoáº¡t venv
```bash
D:\ML-nc\.venv\Scripts\Activate.ps1
```

---

## ğŸ“– TÃ i Liá»‡u Äáº§y Äá»§

- **START_HERE.md** - Äiá»ƒm báº¯t Ä‘áº§u
- **RESULTS_SUMMARY.md** - Káº¿t quáº£ chi tiáº¿t
- **DEPLOYMENT_REPORT.txt** - BÃ¡o cÃ¡o triá»ƒn khai
- **MINIMAX_IMPROVEMENTS.txt** - HÆ°á»›ng dáº«n cáº£i tiáº¿n

---

## ğŸ”— Repository

GitHub: https://github.com/truongminhduc2k4/ML-nc.git

---

**Ready to play! ğŸ®ğŸš€**
Tests the ChessState wrapper class.

### Run All Tests
```bash
python main.py all
```

## Using the Agents

### MCTS Agent
```python
from src.agents import MCTSAgent
from src.chess_engine import ChessState

agent = MCTSAgent(time_limit=5.0)  # 5 seconds per move
state = ChessState()
move = agent.get_move(state)
```

### Random Agent
```python
from src.agents import RandomAgent

agent = RandomAgent()
move = agent.get_move(state)
```

### Minimax Agent
```python
from src.agents import MinimaxAgent

agent = MinimaxAgent(depth=3)  # 3 ply depth
move = agent.get_move(state)
```

## Playing Games

```python
from src.chess_engine import ChessGame
from src.agents import MCTSAgent, RandomAgent

white = MCTSAgent(time_limit=3.0)
black = RandomAgent()

game = ChessGame(white_agent=white, black_agent=black)
result = game.play()
print(f"Result: {result}")
```

## Evaluating Performance

```python
from src.evaluation import Evaluator
from src.agents import MCTSAgent, RandomAgent

evaluator = Evaluator()

# Self-play
mcts = MCTSAgent(time_limit=2.0)
stats = evaluator.self_play(mcts, num_games=10)

# Comparison
random = RandomAgent()
comparison = evaluator.comparison(mcts, random, num_games=5)

# Save report
evaluator.save_report()
```

## Project Structure

- `src/mcts.py` - Core MCTS algorithm with MCTSNode class
- `src/chess_engine.py` - ChessState wrapper and ChessGame manager
- `src/agents.py` - AI agents (MCTS, Random, Minimax, Human, etc.)
- `src/evaluation.py` - Game evaluation and comparison framework
- `main.py` - Example tests and quick start
- `data/` - Game records and statistics (auto-generated)
- `reports/` - Evaluation reports (auto-generated)

## Key Classes

### MCTSNode
- Represents a node in the MCTS search tree
- Stores state, parent, children, visit counts, values
- Implements UCT selection and best child calculation

### MCTS
- Implements Monte Carlo Tree Search algorithm
- 4 main phases: Selection â†’ Expansion â†’ Simulation â†’ Backpropagation
- Configurable time limit or iteration limit

### ChessState
- Wraps python-chess Board for MCTS compatibility
- Provides: get_legal_moves(), apply_move(), is_terminal(), evaluate()
- Compatible with game tree search algorithms

### Agents
- MCTSAgent: Uses MCTS for move selection
- RandomAgent: Selects random legal moves
- MinimaxAgent: Uses minimax with alpha-beta pruning
- HumanAgent: Interactive human player

## Next Steps

1. Run the tests to verify everything works
2. Experiment with different time limits and depths
3. Modify the evaluation functions for better play
4. Add neural network evaluation (AlphaZero-lite)
5. Generate performance reports and visualizations

## Tips

- MCTS performance improves with more time/iterations
- RandomAgent is a weak baseline (good for testing)
- MinimaxAgent with depth=2-3 is reasonable
- Adjust exploration constant (default 1.41) to balance exploration/exploitation
- Use verbose=True to see detailed search information

## Troubleshooting

If you get "module not found" errors:
```bash
pip install -r requirements.txt
```

If games are too slow:
- Reduce MCTSAgent time_limit
- Reduce MinimaxAgent depth
- Use iteration_limit instead of time_limit

If agents make illegal moves:
- Check that get_move() is returning valid moves
- Verify ChessState.get_legal_moves() works correctly
